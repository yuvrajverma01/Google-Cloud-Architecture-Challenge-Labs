# Explore Machine Learning Models with Explainable AI: Challenge Lab

> Launch the lab [here](https://google.qwiklabs.com/focuses/12011?parent=catalog)

## Your challenge

You are a curious coder who wants to explore biases in public datasets using the What-If Tool. You decide to pull some mortgage [data](https://www.consumerfinance.gov/data-research/hmda/historic-data/) to train a couple of machine learning models to predict whether an applicant will be granted a loan. You specifically want to investigate how the two models perform when they are trained on different proportions of males and females in the datasets, and visualize their differences in the What-If Tool.

### Start a JupyterLab Notebook instance

* Storage > Bucket > Create Bucket > Enter the name as your **Project ID** > CREATE

`KEEP ONLY THE INSTANCE OF NOTEBOOK` in `US_WEST1(OREGON)`

* AI Platform > Notebooks > NEW INSTANCE > Use `TensorFlow Enterprise 2.3 Without GPUs` > CREATE

* Wait for it to be created > **Open Jupyterlab** (takes 5 min.)

### Download the Challenge Notebook

* Open `Terminal` in Jupyter Notebook

* Paste the code below and clone the repo

```yaml

git clone https://github.com/GoogleCloudPlatform/training-data-analyst

```

* Go to the enclosing folder: `training-data-analyst/quests/dei`

* Open the notebook file `what-if-tool-challenge.ipynb`

### Build and train your models

* Modify the block 10 as:

```python
model = Sequential()
model.add(layers.Dense(200, input_shape=(input_size,), activation='relu'))
model.add(layers.Dense(50, activation='relu'))
model.add(layers.Dense(20, activation='relu'))
model.add(layers.Dense(1, activation='sigmoid'))
model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])
model.fit(train_data, train_labels, epochs=10, batch_size=2048, validation_split=0.1)
```

* Modify the block 13:

```python
limited_model = Sequential()
limited_model.add(layers.Dense(200, input_shape=(input_size,), activation='relu'))
limited_model.add(layers.Dense(50, activation='relu'))
limited_model.add(layers.Dense(20, activation='relu'))
limited_model.add(layers.Dense(1, activation='sigmoid'))
limited_model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])
limited_model.fit(limited_train_data, limited_train_labels, epochs=10, batch_size=2048, validation_split=0.1)
```

### Deploy the models to AI Platform

* Enter the peoper information block 16.

```python

GCP_PROJECT = '[enter your gcp project id]'
MODEL_BUCKET = 'gs://[project id]'

```

* Last Block (Add below given code in the end)

```python

config_builder = (WitConfigBuilder(
    examples_for_wit[:num_datapoints],feature_names=column_names)
    .set_custom_predict_fn(limited_custom_predict)
    .set_target_feature('loan_granted')
    .set_label_vocab(['denied', 'accepted'])
    .set_compare_custom_predict_fn(custom_predict)
    .set_model_name('limited')
    .set_compare_model_name('complete'))
WitWidget(config_builder, height=800)

```

### Create Models

## Create Model 1 (complete_model)

* Navigation Menu > **AI Platform** > `Models`

* Keep the **Region** as `us-central1`

```yaml

Model Name = complete_model
Region =  `us-central1`

```

* CREATE MODEL

* GO BACK

* Click on `complete_model` now

* Click on `Create a version` now

```yaml

Name = v1
Python version = 3.7
Framework = TensorFlow
Framework version = 2.3.1
ML Runtime version = 2.3

BROWSE > Select GCP ID > Click 'saved_complete_model/' > Click Select below

```

* Click on `SAVE` now

## Create Model 2 (limited_model)

* Click on `Models` on left **Navigation Menu**

* CREATE `NEW MODEL` on top

```yaml

Model Name = limited_model
Region =  `us-central1`

```

* CREATE MODEL

* GO BACK

* Click on `limited_model` now

* Click on `Create a version` now

```yaml

Name = v1
Python version = 3.7
Framework = TensorFlow
Framework version = 2.3.1
ML Runtime version = 2.3

BROWSE > Select GCP ID > Click 'saved_limited_model/' > Click Select below

```

* Click on `SAVE` now

* This will take about 20 minutes to get completed